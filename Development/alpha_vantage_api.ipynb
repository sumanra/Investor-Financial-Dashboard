{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial stock datas using alpha vantage api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pip install MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import datetime as dt\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "pymysql.install_as_MySQLdb()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query Url and List of Stocks ticker\n",
    "# https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=MSFT&outputsize=full&apikey=demo\n",
    "api_url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=\"\n",
    "api_key = \"Y5AE5LOO06SXQ60H\"\n",
    "\n",
    "# List of Stocks ticker\n",
    "tickers = [\"CFG\",\"MS\",\"CME\",\"JPM\",\"GS\",\"PYPL\",\"BRK.A\",\"BRK.B\",\"USB\",\"IBKR\",\"AXP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and initialize list \n",
    "df_list = []\n",
    "stock_symbol = []\n",
    "stock_daily_details = []\n",
    "stock_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tickers:\n",
    "    try:\n",
    "        url = api_url + ticker + \"&outputsize=full&apikey=\" + api_key\n",
    "\n",
    "        stock_details = requests.get(url).json()\n",
    "        stock_symbol = stock_details[\"Meta Data\"][\"2. Symbol\"]\n",
    "        stock_daily_details = stock_details[\"Time Series (Daily)\"]\n",
    "#         print(stock_daily_details)\n",
    "\n",
    "        # Save json data for each API call\n",
    "        with open(f'static/assets/data/output_api_{ticker}.json', 'w') as outfile:\n",
    "            json.dump(stock_daily_details, outfile)\n",
    "            # As our api allow certain number of data to be pulled once so adding the sleep command\n",
    "            time.sleep(30)\n",
    "\n",
    "    # If an error is experienced, skip the ticker\n",
    "    except:\n",
    "        print(\"ticker not found. Skipping...\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CFG_t = pd.read_json(\"static/assets/data/output_api_CFG.json\")\n",
    "df_MS_t = pd.read_json(\"static/assets/data/output_api_MS.json\")\n",
    "df_CME_t = pd.read_json(\"static/assets/data/output_api_CME.json\")\n",
    "df_JPM_t = pd.read_json(\"static/assets/data/output_api_JPM.json\")\n",
    "df_GS_t = pd.read_json(\"static/assets/data/output_api_GS.json\")\n",
    "df_PYPL_t = pd.read_json(\"static/assets/data/output_api_PYPL.json\")\n",
    "df_BRKA_t = pd.read_json(\"static/assets/data/output_api_BRK.A.json\")\n",
    "df_BRKB_t = pd.read_json(\"static/assets/data/output_api_BRK.B.json\")\n",
    "df_USB_t = pd.read_json(\"static/assets/data/output_api_USB.json\")\n",
    "df_IBKR_t = pd.read_json(\"static/assets/data/output_api_USB.json\")\n",
    "df_AXP_t = pd.read_json(\"static/assets/data/output_api_USB.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for Citizens Financial Group (ticker: CFG)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CFG = df_CFG_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_CFG = df_CFG.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend_amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_CFG.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CFG_new = df_CFG[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "df_CFG_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change type to float\n",
    "df_CFG_new = df_CFG_new.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  adding ticker column\n",
    "df_CFG_new ['ticker']= 'CFG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  adding ticker column\n",
    "df_CFG_new ['company_name']= 'Citizens Financial Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindexing \n",
    "df_CFG_new = df_CFG_new.reset_index()\n",
    "df_CFG_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_CFG_new = df_CFG_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CFG_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(df_CFG_new['dates']).apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CFG_new.to_sql(name='cfg_profile', con=engine, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from cfg_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_CFG_new.to_sql(name='CFG_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "# #     con.execute ('DROP TABLE \"CFG_stock\";')\n",
    "#     con.execute('ALTER TABLE \"CFG_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"CFG_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"CFG_stock\";',con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_CFG_new.to_csv('static/assets/csv/CFG_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for  Morgan Stanley (MS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_MS = df_MS_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_MS = df_MS.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_MS_new = df_MS[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_MS_new = df_MS_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_MS_new ['ticker']= 'MS'\n",
    "#  adding ticker column\n",
    "df_MS_new ['company_name']= 'Morgan Stanley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_new = df_MS_new.reset_index()\n",
    "# renaming a column\n",
    "df_MS_new = df_MS_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_new.to_sql(name='ms_profile', con=engine, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from ms_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to local database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_MS_new.to_sql(name='MS_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"MS_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"MS_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_MS = pd.read_sql_query('select * from \"MS_stock\"',con=engine)\n",
    "# df_MS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_MS_new.to_csv('static/assets/csv/MS_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for CME Group (CME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_CME = df_CME_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_CME = df_CME.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_CME_new = df_CME[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_CME_new = df_CME_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_CME_new ['ticker']= 'CME'\n",
    "#  adding ticker column\n",
    "df_CME_new ['company_name']= 'CME Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CME_new = df_CME_new.reset_index()\n",
    "# renaming a column\n",
    "df_CME_new = df_CME_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CME_new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CME_new.to_sql(name='cme_profile', con=engine, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from cme_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_CME_new.to_sql(name='CME_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"CME_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"CME_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"CME_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_CME_new.to_csv('static/assets/csv/CME_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for  JPMorgan Chase & Co. (JPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_JPM = df_JPM_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_JPM = df_JPM.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_JPM_new = df_JPM[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_JPM_new = df_JPM_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_JPM_new ['ticker']= 'JPM'\n",
    "#  adding ticker column\n",
    "df_JPM_new ['company_name']= 'JPMorgan Chase & Co.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JPM_new = df_JPM_new.reset_index()\n",
    "# renaming a column\n",
    "df_JPM_new = df_JPM_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JPM_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JPM_new.to_sql(name='jpm_profile', con=engine, if_exists = 'append', index=False)\n",
    "pd.read_sql_query('select * from jpm_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_JPM_new.to_sql(name='JPM_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"JPM_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"JPM_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"JPM_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_JPM_new.to_csv('static/assets/csv/JPM_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for  Goldman Sachs Group (GS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_GS = df_GS_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_GS = df_GS.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_GS_new = df_GS[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_GS_new = df_GS_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_GS_new ['ticker']= 'GS'\n",
    "#  adding ticker column\n",
    "df_GS_new ['company_name']= 'Goldman Sachs Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GS_new = df_GS_new.reset_index()\n",
    "# renaming a column\n",
    "df_GS_new = df_GS_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GS_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GS_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_GS_new.to_csv('static/assets/csv/GS_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GS_new.to_sql(name='gs_profile', con=engine, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from gs_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_GS_new.to_sql(name='GS_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"GS_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"GS_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"GS_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for  PayPal Holdings (PYPL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_PYPL = df_PYPL_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_PYPL = df_PYPL.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_PYPL_new = df_PYPL[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_PYPL_new = df_PYPL_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_PYPL_new ['ticker']= 'PYPL'\n",
    "#  adding ticker column\n",
    "df_PYPL_new ['company_name']= 'PayPal Holdings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PYPL_new = df_PYPL_new.reset_index()\n",
    "# renaming a column\n",
    "df_PYPL_new = df_PYPL_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PYPL_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_PYPL_new.to_sql(name='PYPL_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"PYPL_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"PYPL_stock\" ALTER COLUMN dates TYPE DATE;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"PYPL_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_PYPL_new.to_csv('static/assets/csv/PYPL_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')\n",
    "\n",
    "df_PYPL_new.to_sql(name='pypl_profile', con=engine, if_exists = 'append', index=False)\n",
    "\n",
    "pd.read_sql_query('select * from pypl_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for  Berkshire Hathaway (BRK.A)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_BRKA = df_BRKA_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_BRKA = df_BRKA.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_BRKA_new = df_BRKA[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_BRKA_new = df_BRKA_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_BRKA_new ['ticker']= 'BRK.A'\n",
    "#  adding ticker column\n",
    "df_BRKA_new ['company_name']= 'Berkshire Hathaway(BRK.A)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BRKA_new = df_BRKA_new.reset_index()\n",
    "# renaming a column\n",
    "df_BRKA_new = df_BRKA_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BRKA_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BRKA_new.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_BRKA_new.to_sql(name='BRKA_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"BRKA_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"BRKA_stock\" ALTER COLUMN dates TYPE DATE;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_BRKA = pd.read_sql_query('select * from \"BRKA_stock\"', con=engine)\n",
    "# df_BRKA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_BRKA_new.to_csv('static/assets/csv/BRKA_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')\n",
    "\n",
    "df_BRKA_new.to_sql(name='brka_profile', con=engine, if_exists = 'append', index=False)\n",
    "\n",
    "pd.read_sql_query('select * from brka_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for  Berkshire Hathaway (BRK.B)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_BRKB = df_BRKB_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_BRKB = df_BRKB.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_BRKB_new = df_BRKB[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_BRKB_new = df_BRKB_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_BRKB_new ['ticker']= 'BRK.B'\n",
    "#  adding ticker column\n",
    "df_BRKB_new ['company_name']= 'Berkshire Hathaway(BRK.B)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BRKB_new = df_BRKB_new.reset_index()\n",
    "# renaming a column\n",
    "df_BRKB_new = df_BRKB_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BRKB_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_BRKB_new.to_sql(name='BRKB_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"BRKB_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"BRKB_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"BRKB_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_BRKB_new.to_csv('static/assets/csv/BRKB_stock_details.csv',index = True, header = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')\n",
    "\n",
    "df_BRKB_new.to_sql(name='brkb_profile', con=engine, if_exists = 'append', index=False)\n",
    "\n",
    "pd.read_sql_query('select * from brkb_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for   U.S. Bancorp (USB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_USB = df_USB_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_USB = df_USB.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_USB_new = df_USB[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_USB_new = df_USB_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_USB_new ['ticker']= 'USB'\n",
    "#  adding ticker column\n",
    "df_USB_new ['company_name']= 'U.S. Bancorp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_USB_new = df_USB_new.reset_index()\n",
    "# renaming a column\n",
    "df_USB_new = df_USB_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_USB_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_USB_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_USB_new.to_sql(name='USB_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"USB_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"USB_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"USB_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_USB_new.to_csv('static/assets/csv/USB_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')\n",
    "\n",
    "df_USB_new.to_sql(name='usb_profile', con=engine, if_exists = 'append', index=False)\n",
    "\n",
    "pd.read_sql_query('select * from usb_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for  Interactive Brokers (IBKR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_IBKR = df_IBKR_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_IBKR = df_IBKR.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_IBKR_new = df_IBKR[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\"]].copy()\n",
    "# change type to float\n",
    "df_IBKR_new = df_IBKR_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_IBKR_new ['ticker']= 'IBKR'\n",
    "#  adding ticker column\n",
    "df_IBKR_new ['company_name']= 'Interactive Brokers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IBKR_new = df_IBKR_new.reset_index()\n",
    "# renaming a column\n",
    "df_IBKR_new = df_IBKR_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IBKR_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IBKR_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_IBKR_new.to_sql(name='IBKR_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"IBKR_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"IBKR_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"IBKR_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_IBKR_new.to_csv('static/assets/csv/IBKR_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')\n",
    "\n",
    "df_IBKR_new.to_sql(name='ibkr_profile', con=engine, if_exists = 'append', index=False)\n",
    "\n",
    "pd.read_sql_query('select * from ibkr_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning datas for American Express Co. (AXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the dataframe\n",
    "df_AXP = df_AXP_t.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming a column\n",
    "df_AXP = df_AXP.rename(columns={'1. open': 'open','2. high': 'high','3. low': 'low','4. close': 'close',\n",
    "                            '5. adjusted close': 'adjusted_close','6. volume': 'volume',\n",
    "                            '7. dividend amount': 'dividend amount','8. split coefficient': 'split coefficient'})\n",
    "\n",
    "df_AXP_new = df_AXP[[\"open\", \"high\", \"low\",\"close\",\"adjusted_close\",\"volume\",]].copy()\n",
    "# change type to float\n",
    "df_AXP_new = df_AXP_new.astype(float)\n",
    "#  adding ticker column\n",
    "df_AXP_new ['ticker']= 'AXP'\n",
    "#  adding ticker column\n",
    "df_AXP_new ['company_name']= 'American Express Co.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AXP_new = df_AXP_new.reset_index()\n",
    "# renaming a column\n",
    "df_AXP_new = df_AXP_new.rename(columns={'index': 'dates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AXP_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AXP_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_AXP_new.to_sql(name='AXP_stock', con=engine, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to add the auto increament primary key \"id\"\n",
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"AXP_stock\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"AXP_stock\" ALTER COLUMN dates TYPE DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"AXP_stock\"', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_AXP_new.to_csv('static/assets/csv/AXP_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')\n",
    "\n",
    "df_AXP_new.to_sql(name='axp_profile', con=engine, if_exists = 'append', index=False)\n",
    "\n",
    "pd.read_sql_query('select * from axp_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concating the dataframe to eventually make a final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_CFG_new,df_MS_new,df_CME_new,df_JPM_new,df_GS_new,df_PYPL_new,df_BRKA_new,df_BRKB_new,df_USB_new,df_IBKR_new,df_AXP_new]).drop_duplicates()\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting values of dates in decending order\n",
    "df_sort = df_final.sort_values(['dates'], ascending=[False])\n",
    "# to do reset index\n",
    "df_stock = df_sort.reset_index()\n",
    "df_stock.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stock = df_stock[[\"dates\", \"open\", \"high\", \"low\", \"close\", \"adjusted_close\", \"volume\", \"ticker\",\"company_name\"]].copy()\n",
    "df_stock.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to heroku-postgresql database and load converted DataFrame into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = create_engine('postgres://xceiqrenotzqbw:a808f4c0025de8def28e3634b65274076745bd42160a69e04f794faa8667a092@ec2-50-19-254-63.compute-1.amazonaws.com:5432/d1fj3p42e5lp7k')\n",
    "# df_stock.to_sql(name='Stock_all', con=engine, if_exists = 'replace', index=False)\n",
    "# with engine.connect() as con:\n",
    "#     con.execute(' ALTER TABLE \"Stock_all\" ADD COLUMN id SERIAL PRIMARY KEY;')\n",
    "#     con.execute('ALTER TABLE \"Stock_all\" ALTER COLUMN dates TYPE DATE;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('select * from \"Stock_all\"', con=engine).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final stock dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally putting transformed dataframe to csv file\n",
    "df_stock.to_csv('static/assets/csv/Merged_stock_details.csv',index = True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MYSQL database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stockml_db')\n",
    "#engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_stock[:10000].to_sql(name='stocks_profile', con=engine, if_exists = 'append',index=False)\n",
    "\n",
    "#pd.read_sql_query('select * from stocks_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from stocks_profile', con=engine).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from stocks_profile', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
