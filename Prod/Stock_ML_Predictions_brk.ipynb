{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import sys\n",
    "import csv\n",
    "import datetime\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "pymysql.install_as_MySQLdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "#for normalizing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stock_data')\n",
    "# df = pd.read_sql_query('select * from profile', con=engine)\n",
    "cfg_data = pd.read_sql_query('select * from cfg_data', con=engine)\n",
    "ms_data = pd.read_sql_query('select * from ms_data', con=engine)\n",
    "cme_data = pd.read_sql_query('select * from cme_data', con=engine)\n",
    "jpm_data = pd.read_sql_query('select * from jpm_data', con=engine)\n",
    "gs_data = pd.read_sql_query('select * from gs_data', con=engine)\n",
    "pypl_data = pd.read_sql_query('select * from pypl_data', con=engine)\n",
    "td_data = pd.read_sql_query('select * from td_data', con=engine)\n",
    "brk_data = pd.read_sql_query('select * from brk_data', con=engine)\n",
    "usb_data = pd.read_sql_query('select * from usb_data', con=engine)\n",
    "ibkr_data = pd.read_sql_query('select * from ibkr_data', con=engine)\n",
    "axp_data = pd.read_sql_query('select * from axp_data', con=engine)\n",
    "tech_data = pd.read_sql_query('select * from tech_data', con=engine)\n",
    "spx_data = pd.read_sql_query('select * from spx_data', con=engine)\n",
    "dow_data = pd.read_sql_query('select * from dow_data', con=engine)\n",
    "nasdaq_data = pd.read_sql_query('select * from nasdaq_data', con=engine)\n",
    "vix_data = pd.read_sql_query('select * from vix_data', con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbols</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>axp</td>\n",
       "      <td>128.679993</td>\n",
       "      <td>127.760002</td>\n",
       "      <td>128.250000</td>\n",
       "      <td>128.570007</td>\n",
       "      <td>2355700.0</td>\n",
       "      <td>128.570007</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>axp</td>\n",
       "      <td>129.339996</td>\n",
       "      <td>127.800003</td>\n",
       "      <td>129.220001</td>\n",
       "      <td>128.059998</td>\n",
       "      <td>2734000.0</td>\n",
       "      <td>128.059998</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>axp</td>\n",
       "      <td>128.639999</td>\n",
       "      <td>127.010002</td>\n",
       "      <td>128.020004</td>\n",
       "      <td>127.080002</td>\n",
       "      <td>2248900.0</td>\n",
       "      <td>127.080002</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>axp</td>\n",
       "      <td>129.089996</td>\n",
       "      <td>126.660004</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>128.399994</td>\n",
       "      <td>3524500.0</td>\n",
       "      <td>128.399994</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>axp</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>123.800003</td>\n",
       "      <td>126.800003</td>\n",
       "      <td>124.820000</td>\n",
       "      <td>7369624.0</td>\n",
       "      <td>124.820000</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbols        High         Low        Open       Close  \\\n",
       "1259 2019-07-15     axp  128.679993  127.760002  128.250000  128.570007   \n",
       "1260 2019-07-16     axp  129.339996  127.800003  129.220001  128.059998   \n",
       "1261 2019-07-17     axp  128.639999  127.010002  128.020004  127.080002   \n",
       "1262 2019-07-18     axp  129.089996  126.660004  126.690002  128.399994   \n",
       "1263 2019-07-19     axp  128.000000  123.800003  126.800003  124.820000   \n",
       "\n",
       "         Volume   Adj Close              Company_name  \n",
       "1259  2355700.0  128.570007  American Express Company  \n",
       "1260  2734000.0  128.059998  American Express Company  \n",
       "1261  2248900.0  127.080002  American Express Company  \n",
       "1262  3524500.0  128.399994  American Express Company  \n",
       "1263  7369624.0  124.820000  American Express Company  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axp_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setting index as date\n",
    "# brk_data['Date'] = pd.to_datetime(brk_data.Date,format='%Y-%m-%d')\n",
    "# brk_data.index = ibkr_data['Date']\n",
    "\n",
    "# #plot\n",
    "# plt.figure(figsize=(16,8))\n",
    "# plt.plot(ibkr_data['Close'], label='Close Price history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = ibkr_data.sort_index(ascending=True, axis=0)\n",
    "# new_data = pd.DataFrame(index=range(0,len(ibkr_data)),columns=['Date', 'Close'])\n",
    "# for i in range(0,len(data)):\n",
    "#     new_data['Date'][i] = data['Date'][i]\n",
    "#     new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "# #setting index\n",
    "# new_data.index = new_data.Date\n",
    "# new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# #creating train and test sets\n",
    "# dataset = new_data.values\n",
    "# data.iloc[1000:1010]\n",
    "# # train = dataset[0:987,:]\n",
    "# # valid = dataset[987:,:]\n",
    "\n",
    "# train = dataset[0:1007,:]\n",
    "# valid = dataset[1007:,:]\n",
    "\n",
    "# #converting dataset into x_train and y_train\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# x_train, y_train = [], []\n",
    "# # 60 variance\n",
    "# for i in range(60,len(train)):\n",
    "#     x_train.append(scaled_data[i-60:i,0])\n",
    "#     y_train.append(scaled_data[i,0])\n",
    "# x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # create and fit the LSTM network\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "# model.add(LSTM(units=50))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "# #predicting 246 values, using past 60 from the train data\n",
    "# inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "# inputs = inputs.reshape(-1,1)\n",
    "# inputs  = scaler.transform(inputs)\n",
    "\n",
    "# X_test = []\n",
    "# for i in range(60,inputs.shape[0]):\n",
    "#     X_test.append(inputs[i-60:i,0])\n",
    "# X_test = np.array(X_test)\n",
    "\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "# closing_price = model.predict(X_test)\n",
    "# closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "# rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbols</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>brk-a</td>\n",
       "      <td>321500</td>\n",
       "      <td>319455</td>\n",
       "      <td>321500</td>\n",
       "      <td>320300.0</td>\n",
       "      <td>100</td>\n",
       "      <td>320300.0</td>\n",
       "      <td>Berkshire Hathaway Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>brk-a</td>\n",
       "      <td>322300</td>\n",
       "      <td>319250</td>\n",
       "      <td>321040</td>\n",
       "      <td>319273.0</td>\n",
       "      <td>200</td>\n",
       "      <td>319273.0</td>\n",
       "      <td>Berkshire Hathaway Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>brk-a</td>\n",
       "      <td>318500</td>\n",
       "      <td>311115</td>\n",
       "      <td>318325</td>\n",
       "      <td>311600.0</td>\n",
       "      <td>500</td>\n",
       "      <td>311600.0</td>\n",
       "      <td>Berkshire Hathaway Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>brk-a</td>\n",
       "      <td>313595</td>\n",
       "      <td>310770</td>\n",
       "      <td>310770</td>\n",
       "      <td>312003.0</td>\n",
       "      <td>600</td>\n",
       "      <td>312003.0</td>\n",
       "      <td>Berkshire Hathaway Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>brk-a</td>\n",
       "      <td>312875</td>\n",
       "      <td>309200</td>\n",
       "      <td>312600</td>\n",
       "      <td>309217.5</td>\n",
       "      <td>269</td>\n",
       "      <td>309217.5</td>\n",
       "      <td>Berkshire Hathaway Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbols    High     Low    Open     Close  Volume  Adj Close  \\\n",
       "1259 2019-07-15   brk-a  321500  319455  321500  320300.0     100   320300.0   \n",
       "1260 2019-07-16   brk-a  322300  319250  321040  319273.0     200   319273.0   \n",
       "1261 2019-07-17   brk-a  318500  311115  318325  311600.0     500   311600.0   \n",
       "1262 2019-07-18   brk-a  313595  310770  310770  312003.0     600   312003.0   \n",
       "1263 2019-07-19   brk-a  312875  309200  312600  309217.5     269   309217.5   \n",
       "\n",
       "                 Company_name  \n",
       "1259  Berkshire Hathaway Inc.  \n",
       "1260  Berkshire Hathaway Inc.  \n",
       "1261  Berkshire Hathaway Inc.  \n",
       "1262  Berkshire Hathaway Inc.  \n",
       "1263  Berkshire Hathaway Inc.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# df_data = [\"cfg_data\",\"ms_data\",\"cme_data\",\"jpm_data\",\"gs_data\",\"pypl_data\",\"td_data\",\"brk_data\",\"usb_data\",\"ibkr_data\",\"axp_data\"]\n",
    "\n",
    "data = pypl_data.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(pypl_data)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(data)):\n",
    "    new_data['Date'][i] = data['Date'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "# train = dataset[0:987,:]\n",
    "# valid = dataset[987:,:]\n",
    "\n",
    "train = dataset[0:1004,:]\n",
    "valid = dataset[1004:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n",
    "\n",
    "valid = new_data[1004:]\n",
    "valid['Predictions'] = closing_price\n",
    "ml_data = valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "# train = new_data[:1004]\n",
    "valid = new_data[1004:]\n",
    "valid['Predictions'] = closing_price\n",
    "# plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1000:1015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data['Symbols']= 'pypl'\n",
    "ml_data = ml_data.reset_index()\n",
    "ml_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "# train = new_data[:1004]\n",
    "valid = new_data[1004:]\n",
    "valid['Predictions'] = closing_price\n",
    "# plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading into Database Mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stock_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_data.to_sql(name='cfg_data_LSTM', con=engine, if_exists = 'replace', index=False)\n",
    "# ml_data.to_sql(name='ms_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='cme_data_lstm', con=engine, if_exists = 'replace', index=False)\n",
    "# ml_data.to_sql(name='jpm_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='gs_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "ml_data.to_sql(name='pypl_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='td_data_lstm', con=engine, if_exists = 'replace', index=False)\n",
    "## ml_data.to_sql(name='brk_data_LSTM', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='usb_data_LSTM', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='ibkr_data_LSTM', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='axp_data_LSTM', con=engine, if_exists = 'replace', index=False)\n",
    "# ml_data.to_sql(name='tech_data_LSTM', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='all_data_LSTM', con=engine, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from pypl_data_lstm', con=engine).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypl_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
